---
title: "All data processing"
date: "`r Sys.Date()`"
#output:
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
#output:
#  html_document:
#    css: styles.css 
---

<style>
.text-box {
  background-color: #d4e9fc;
  color: black;
  font-size: 14px;
  border-radius: 5px; 
  padding: 20px
}
</style>

<style>
.lecture-box {
  background-color: #f7e1fc;
  color: black;
  font-size: 14px;
  border-radius: 5px; 
  padding: 20px
}
</style>

# processing data


When the data comes back from the sequencer, it is one giant text file in fastq format that includes all data from your lane of sequencing. Remember about barcodes- we can use these to demultiplex our data (or really the sequencing center will do it for you, depending on your data type). 

In general, you'll take some fairly consistent steps, with a lot of options, to process your data so you can get to the point of calling snps. These are: quality control, cleaning, and mapping.

For our purposes will use just one sample to learn about data processing. This is sample, `TR-023`, which is  randomly chosen. After demultiplexing, we have two files associated with this sample: `TR-023_RA.fastq.gz` and `TR-023_RB.fastq.gz`


<div class="text-box">

Why do we have two files for one sample?

</div>

example of fastq format:

```
@J00113:190:HFV3LBBXX:7:1101:3742:1297 1:N:0:NAGCTT
TGCAGGCTCAGTCCTGATGAGGGAGCCATCTTTATAGAAAGCAGCTGGGAGGTTGGAGGGAGCGGTCTTTGTGTGACAGCTCAGAGTGACGGCAGCTCCCTCCATCACATGGAGTACAGGATTCTGCATGATTTCTGATC
+
FJJJJFJJJFJFJJJJAJJ-FJJFFJJJAAAAF-<AJFFFFJJJFAFFF<A7-<FFAJJJJ<JAJ7A<AJFJJJJJJJJJA-FAJA-AAFF<AF-F--AF7FAJJ77-7JJJA-7--AJJA-AFFF-----<--7--777
@J00113:190:HFV3LBBXX:7:1101:13738:1314 1:N:0:NAGCTT
TGCAGGACTCGTTGTTGATGAGGAAATGGTCACCACATGCTGACATTGTGGGTAAGCCAGTATTTCAAATAGTGGTTCCCAGAAAACTCCGTTCTGCAGTGTGAAAAGTTGCTCTTGATGAGTCTGGTCATTCTGGTGTA
+
JJJJJJJJJJJJJJJJJFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJJJ<FJ7FJJJFJJJJJJJFJJJJJJ-<FFFJJJ-A-F)7<J-7<-<F-AFJ
@J00113:190:HFV3LBBXX:7:1101:19015:1314 1:N:0:NAGCTT
TGCAGGTTTAAGCTCAGAAGACGACGCCCCTGCACTGAAATACAGGAAGAAGATCTGCATGAACCAGCCTCACCTGCGGTTTGAAATCACCAGCGAGGACGGCTTCAGCGTTAAGGCTAACAGCATAGAGGGTAGGAGTG

```

In the fastq file, each read consists of 4 lines:

1. A sequence identifier with information about the sequencing run and the sequence
2. The actual sequence
3. A separator (+)
4. the quality scores.

You can look at your fastq file yourself. However, these are gz files. Try to look at them with `head`. 

You need to use `zcat your_fastqFile`. Warning! This will print your whole file! You can do this and see what happens.  `control + c` will cancel the printing. 

Instead, we need to use `|`, or a pipe. So we can pipe the output of `zcat` to another command, in this case `head`. 

`zcat TR-023_RA.fastq.gz  | head`

We can also count how many lines are in our file. you do this with `wc -l`. 

<div class="text-box">

Use `zcat`, `|`, and `wc -l` to count the number of reads in your fastq files.  

- How many reads do you have?   
- Do the number of forward and reverse reads agree? Why?

</div>

## check quality

We will use [fastqc](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) to check the quality of our sequencing. Briefly, this program scans our fastq files and checks for quality, contamination from adapters, and sequence bias, among others. 

Look at the help page of fastqc using `fastqc --help`

We can then run fastqc for our forward read: 

```bash
fastqc course_materials/TR-023_RA.fastq.gz -o .
```

<div class="text-box">
- Modify the above code to run fastqc on your reverse read.
- Discuss the output of fastqc together.
</div>

## trim

We don't have much evidence for adapter contamination with this sample, but we do see evidence for some quality issues, which are normal. We can deal with these issues by trimming. Note, this isn't totally necessary in all cases as many alignment software can deal with low quality bases.

We will use [Trim Galore](https://www.bioinformatics.babraham.ac.uk/projects/trim_galore/) to clean up our data. There are many programs you can use for this- we're using Trim Galore because it is relatively simple and because it auto detects adapters. 

Below is the code to run this program. Again, you can get help using `trim_galore --help`

```{bash, eval=F}
trim_galore --paired \
      course_materials/TR-023_RA.fastq.gz \
      course_materials/TR-023_RB.fastq.gz \
      -q 30 --length 30 --stringency 4
```

<div class="text-box">

After trim_galore finishes, run fastqc on your newly trimmed data. 

- What has changed? Anything? 
- Change the stringency, quality, or length threshold in your trim_galore command. How has this affected your results?

</div>

## align to reference genome

We're not actually doing this! 

<div class="lecture-box">

Short lecture on alignment, reference genomes, and Stacks.

</div>


### Understanding mapping output

Output files are in *sam* or *bam* format where bam files are compressed versions of sam files. 

<div class = "text-box">

Use `head` to look at your bam output. What do you see?

</div>

We need to use another program, `samtools` to look at our bam file. Again, use `samtools --help` or just `samtools` to get an overview of this program. 

The most basic tool in samtools is `samtools view`, which  prints the bam file in plain text. You can see the help page with `samtools view --help`.

the basic syntax is: `samtools view NAME.bam`.... remeber `head` and `|`. 

<div class = "text-box">
Look at your bam file using samtools.
</div>

You should see something like this:

```
J00113:190:HFV3LBBXX:7:1223:20912:25914 163     NW_012224401.1  27218   60      150M    =       27487   409     CACACAGCTGCTGAGTAGCCAGAATATGAAAAGCAGTGTCAAGCTGTTCATATCTGGGTAAAGTTTTGAGTTTGGAAACGTATCTACAGCTGATATTACATGGTTATAATACACTGATTGATGAGCGTCTTTTCTCTGACTCATCCTGGT  AAFFFJJJJJJJJJJFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJJJJJJJJJJJJJJJJAJJJJJJJJJJJJJJJJJFJJFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJAFJJJJJFFJF<FFJJJJJJJJJJJJJJJJJ      NM:i:1  MD:Z:60G89      AS:i:145        XS:i:115    RG:Z:AC-3-TR-023-023

```

So what's going on in this file? Its a lot to digest. 

```{r echo=FALSE}
library(knitr)

df <- data.frame(
  Col = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16),
  Field = c("QNAME", "FLAG", "RNAME", "POS", "MAPQ", "CIGAR", "RNEXT", "PNEXT", "TLEN", "SEQ", "QUAL", "NM:i:count", "MD:Z:", "AS:i:score", "XS:i:score", "RG:Z:readgroup"),
  Brief_description = c("Query template NAME", "bitwise FLAG", "References sequence NAME", "1-based leftmost mapping POSition", "MAPping Quality", "CIGAR string", "Ref. name of the mate/next read", "Position of the mate/next read", "observed Template LENgth", "segment SEQuence", "ASCII of Phred-scaled base QUALity plus 33", "Number of differences  between the sequence and reference", "String encoding mismatched and deleted reference bases", "Alignment score generated by aligner", "Seconday alignment score", "Read group identification"),
  our_read = c("J00113:190:HFV3LBBXX:7:1223:20912:25914", "163", "NW_012224401.1", "27218", "60", "150M", "=", "27487", "409", "CACACAG...", "AAFFFFJ...", "NM:i:1", "MD:Z:60G89", "AS:i:145", "XS:i:115", "RG:Z:AC-3-TR-023-023")
)

kable(df, format = "markdown")

```

### overall alignment statistics

The easiest way to look at how well our mapping worked is to use `samtools flagstat TR-023.bam`, which gives us this output:

```
1147073 + 0 in total (QC-passed reads + QC-failed reads)
1124360 + 0 primary
0 + 0 secondary
22713 + 0 supplementary
238412 + 0 duplicates
234206 + 0 primary duplicates
1127675 + 0 mapped (98.31% : N/A)
1104962 + 0 primary mapped (98.27% : N/A)
1124360 + 0 paired in sequencing
562180 + 0 read1
562180 + 0 read2
1003448 + 0 properly paired (89.25% : N/A)
1097766 + 0 with itself and mate mapped
7196 + 0 singletons (0.64% : N/A)
86662 + 0 with mate mapped to a different chr
53567 + 0 with mate mapped to a different chr (mapQ>=5)
```

<div class = "lecture-box">
Short lecture/discussion on these results

https://www.molecularecologist.com/2016/08/25/the-trouble-with-pcr-duplicates/

https://hbctraining.github.io/Intro-to-rnaseq-hpc-O2/lessons/04_alignment_quality.html

</div>

#### A more in-depth look

Remember the flags in your bam file? You can filter your reads based on this (which is  what `samtools flagstat` is doing). However, we can be more specific. The syntax to do this is: `samtools view -f # TR-023.bam`. Where `-f` can also be `-F` and `#` is the flag you want to use. 

`-f` to find the reads that agree with the flag statement
`-F` to find the reads that do not agree with the flag statement

At [this website](http://broadinstitute.github.io/picard/explain-flags.html) you can generate any flag definition you want (or get a flag explained). 

<div class = "text-box">

Go to http://broadinstitute.github.io/picard/explain-flags.html

How would you find the number of mapped reads in your bam file? Does this number agree with `samtools flagstat`?

You can also filter by quality by adding a `-q 20` option. A score of 20 is a common threshold. Count the number of mapped reads with q of 20. What do you find?

We can also look at the mapping quality overall:

```
samtools view TR-023.bam | cut -f 5 > mapq.txt
```

Plot a histogram of these mapping qualities in R (hint, just use `hist()`).

</div>

https://www.slideshare.net/lindenb/ngsformats?ref=http://plindenbaum.blogspot.com/2013/09/presentation-file-formats-for-next.html?m=1


##### call snps

Not doing this!

<div class = "lecture-box">

Short snp calling lecture

</div>


# working with SNP data

The most common file format for SNPs is VCF. 

~/admixture_mapping/variants/all.chrom.vcf.gz

vcftools

## filter snps

https://www.ddocent.com/filtering/
https://evomics.org/wp-content/uploads/2022/06/Population-Genomics-Lab-1.pdf

### pca

add snp ids:

chr1_29988

need to get format right. its annoying.

```bash

zcat variants.vcf.gz | grep -v '^#' > variants_noheader.vcf

grep -v "NW_" variants_noheader.vcf > variants_noheader.vcf2
grep -Ew "chr1|chr2|chr3|chr4|chr5" variants_noheader.vcf2 > variants_noheader.vcf3

mv variants_noheader.vcf3 variants_noheader.vcf
rm variants_noheader.vcf2

zcat variants.vcf.gz | grep '^#' > header.txt

cut -f 1 variants_noheader.vcf  > chr.txt
cut -f 2 variants_noheader.vcf | paste chr.txt - -d ":" > snp_id.txt
cut -f 1-2 variants_noheader.vcf | paste - snp_id.txt > threecols.txt
cut -f 4- variants_noheader.vcf | paste threecols.txt - | cat header.txt - > all.vcf




```

```bash
/plink --vcf all.vcf --out variants_pruned \
--indep-pairwise 50 5 0.2 --allow-extra-chr --double-id
```

REWRITE THIS: This command is removing SNPs in linkage using the -â€“indep-pairwise option. The numbers
after the option control how plink removes these SNPs. The first number is the window size (in the
number of variants it investigates). The second number is the frame-shift for the window size (how
many variants the window will move between analysis). The third number is the r2 cut-off value
(designating an upper limit for how correlated/in-linkage SNPs in a window are allowed to be). 50
5 and 0.2 are commonly used values

make the pruned file:

```bash
/plink --vcf all.vcf \
--extract variants_pruned.prune.in \
--make-bed --out variants_NoLD \
--allow-extra-chr --double-id
```

run the pca
```bash
/plink --bfile variants_NoLD \
--pca --out variants_NoLD_PCA --allow-extra-chr --double-id
```


plot the pca results
```{r, eval=F}

library(ggplot2)

setwd("~/Documents/GEOMAR/Teaching/Mar_pop_gen/2023/teaching")

dat <- read.table("variants_NoLD_PCA.eigenvec", header=F)

colnames(dat) <- c("ID", "ID2", "PC1", "PC2", "PC3", "PC4", colnames(dat)[7:ncol(dat)])

dat$population <- substr(dat$ID, 1,2)

d <- ggplot(dat, aes(PC1, PC2, fill=population)) +
        geom_point(size=4.5, shape=21, color="black") +
        #xlab(paste0("PC1: ",percentVar[1],"% variance")) +
        #ylab(paste0("PC2: ",percentVar[2],"% variance")) +
        theme_bw() +
        #scale_fill_manual(values=c('steelblue1','steelblue','grey45', "darkorchid2", "firebrick3"),
  scale_fill_manual(values=c("#D3DDDC",'#6699CC',"#F2AD00","#00A08A", "#CC3333"),
                    labels = c("Founding population","Ambient", "Acidic", 
                               "Warming", "Greenhouse"))+
        #theme(legend.title = element_blank())+
       # theme(legend.text=element_text(size=8))+
        #theme(legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid'))+
#        ggtitle("F1")+
        #fill=c('steelblue1','steelblue','grey45', "darkorchid2", "firebrick3" )),order = 2),
    fill=c("#D3DDDC",'#6699CC',"#F2AD00","#00A08A", "#CC3333")),order = 2),
    shape= FALSE)

#ggsave("~/tonsa_genomics/figures/pca_afs_noF3.pdf",d, w=5.5, h=3.7)

```




### admixture

short lecture on population structure, Fst, drift.


```{bash, eval=F}

for K in 1 2 3 4 5 6; \
do admixture --cv variants_NoLD.bed $K | tee log${K}.out; done

```

```{r, eval=F}

samplelist <- read_tsv("~/Documents/GEOMAR/Teaching/Mar_pop_gen/2023/teaching/indivs_subsample.txt",
                       col_names = "sample")

read_delim("~/Documents/GEOMAR/Teaching/Mar_pop_gen/2023/teaching/variants_NoLD.2.Q",
                  col_names = paste0("Q",seq(1:2)),
                  delim=" ")


# read in all date, in a loop
all_data <- tibble(sample=character(),
                   k=numeric(),
                   Q=character(),
                   value=numeric())

head(all_data)

for (k in 1:6){
  data <- read_delim(paste0("~/Documents/GEOMAR/Teaching/Mar_pop_gen/2023/teaching/variants_NoLD.",k,".Q"),
                  col_names = paste0("Q",seq(1:k)),
                  delim=" ")
  data$sample <- samplelist$sample
  data$k <- k
  #This step converts from wide to long.
  data %>% gather(Q, value, -sample,-k) -> data
  all_data <- rbind(all_data,data)
}

# add the population label
all_data$population <- substr(all_data$sample, 1, 2)
all_data$population <- factor(all_data$population, 
                              levels=c("GA", "PL", "HP", "BC", "PC", "TR"))

# our orders are off in our vcf. lets re-order these from south to north. 
orderlist <- read_tsv("~/Documents/GEOMAR/Teaching/Mar_pop_gen/2023/teaching/population_order.txt",
                       col_names = "sample")
all_data$sample<-factor(all_data$sample,levels=orderlist$sample)

all_data %>%
  filter(k == 2) %>%
  ggplot(.,aes(x=sample,y=value,fill=factor(Q))) + 
  geom_rug(aes(x=sample, y=value, color=population)) +
  geom_bar(stat="identity",position="stack") +
  xlab("Sample") + ylab("Ancestry") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_fill_brewer(palette="Set1",name="K",
                    labels=c("1","2"))

# plot all k values.
p <-  ggplot(all_data,aes(x=sample,y=value,fill=factor(Q))) + 
  geom_bar(stat="identity",position="stack") +
  geom_rug(aes(x=sample, color=population), inherit.aes=F) +
  xlab("Sample") + ylab("Ancestry") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  scale_fill_brewer(palette="Set1",name="K",
                    labels=seq(1:5)) +
  facet_wrap(~k,ncol=1)



ggsave("Admixture_plot.pdf", p, width = 7, height = 15, units="in")

```


### fst

can do big windows, then selection scan?


https://owensgl.github.io/biol525D/Topic_8-9/fst.html

```bash

vcftools --gzvcf all.vcf \
--weir-fst-pop TR.pop \
--weir-fst-pop GA.pop \
--fst-window-size 25000 --out TR_GA_25kb

```

plot the pairwise fst density plots

```{r, class.source = 'fold-hide', eval=F}

# read in all in a list

take all, merge, make ridgeplot for each.
a
a
a
a
a


```

plot correlation plots

### diversity

these run decently fast. 


```{bash, eval=F}
for pop in TR PC BC HP PL GA;
do
  vcftools --vcf all.vcf \
    --keep ${pop}.pop \
    --window-pi 50000 \
    --out ${pop}_pi_50kb;
done
```

```{r, eval=F}

# read in all in a list

#take all, merge, make ridgeplot for each. 



```




## gene environment associations or selection scans.

baypass? bayenv? lfmm? pcadapt is probably easiest. 


## gwas

gemma? 

## intersection between the two?


# things to do:

consider parsing down to fewer chromosomes

Asmixture runs too slow. drop some samples? 

R libraries:
ggplot2
ggridges

drop the funny sample PC-393-024
Probably drop PL- it is confusing.

fix the error in the vcf header that gets thrown with VCFtools.

